#!/bin/bash
# danbing-raava 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() (or any entry point you may add) is
# ALWAYS executed, followed by running the entry point itself.
#
# See https://documentation.dnanexus.com/developer for tutorials on how
# to modify this file.

get_id() {
    echo $1 | awk '{split($2,vs,"\""); print vs[2]}'
}

main() {

	set -eux
    echo "Value of all_inputs: '$all_inputs'"
    echo "Value of o: '$o'"
    echo "Value of docker_image: '$docker_image'"
    #echo "Value of ref: '$ref'"
    #echo "Value of rpgg: '$rpgg'"
    echo "Value of fa: '$fa'"
    #echo "Value of raava_meta_model: '$raava_meta_model'"
    #echo "Value of sex: '$sex'"

    # The following line(s) use the dx command-line tool to download your file
    # inputs to the local file system using variable names for the filenames. To
    # recover the original filenames, you can use the output of "dx describe
    # "$variable" --name".

    projid="project-GppXbfQJggvF80ggJyVYQVXq"
    echo "project id: '$projid'"

	echo "downloading all inputs"
    dx download $projid:$(get_id "$all_inputs") -o all_inputs

	echo "downloading docker image"
    dx download $projid:$(get_id "$docker_image") -o docker_image

	date
	echo "downloading fa"
    dx download $projid:$(get_id "$fa") -o sample.cram

	#sid=$(basename $fa | awk '{split($1,vs,"."); print vs[1]}')
	#echo "sample id $sid"

	QC=20250425b.bool.txt
	sex=1

    ls
    pwd
    date

    # Fill in your application code here.
	tar -xvf all_inputs
	date
    imageid=$(docker load --input docker_image | awk '{split($4,vs,":"); print vs[2]}')
    docker run -i --rm  --mount type=bind,src=/home/dnanexus,dst=/mnt  $imageid  /bin/bash -c \
        "set -eux && cd /mnt &&
		 mkdir -p ~/.cache && mv hts-ref ~/.cache/ &&
         date && samtools fastq -n -@7 sample.cram | danbing-tk -ka -qc $QC -bu -b -qs pan -fq /dev/stdin -o test_g -p 8 && date &&
		 mv best_br_SVM.1ft_rc1_v4_2.gc1_100.gc2_3.TH_15.C_5.W_1.8.TH1_3.TH2_6.TH3_2.W1_10.pickle br_svm &&
		 mv best_bp_SVM.1ft_rc1_v4_2.gc1_100.gc2_3.TH_15.C_5.W_1.8.TH1_3.TH2_6.TH3_2.W1_10.pickle bp_svm &&
		 rarevar.call.py  .  .  .  test_g  hs1.100.3.aln.f1.tsv  br_svm  bp_svm  30488  29589  $sex  10  3  6  2  15000 &&
		 date"


    # To report any recognized errors in the correct format in
    # $HOME/job_error.json and exit this script, you can use the
    # dx-jobutil-report-error utility as follows:
    #
    #   dx-jobutil-report-error "My error message"
    #
    # Note however that this entire bash script is executed with -e
    # when running in the cloud, so any line which returns a nonzero
    # exit code will prematurely exit the script; if no error was
    # reported in the job_error.json file, then the failure reason
    # will be AppInternalError with a generic error message.

    # The following line(s) use the dx command-line tool to upload your file
    # outputs after you have created them on the local file system.  It assumes
    # that you have used the output field name for the filename for each output,
    # but you can change that behavior to suit your needs.  Run "dx upload -h"
    # to see more options to set metadata.

    tr_dosage=$(dx upload test_g.tr.summary.txt --brief)
    kmer_dosage=$(dx upload test_g.trkmc.ar --brief)
    call=$(dx upload test_g.rarevar.pickle --brief)

    # The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.

    dx-jobutil-add-output tr_dosage "$tr_dosage" --class=file
    dx-jobutil-add-output kmer_dosage "$kmer_dosage" --class=file
    dx-jobutil-add-output call "$call" --class=file
}
